{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724a58ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chart_studio in c:\\users\\user\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: plotly in c:\\users\\user\\anaconda3\\lib\\site-packages (from chart_studio) (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from chart_studio) (2.31.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from chart_studio) (1.3.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from chart_studio) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from plotly->chart_studio) (8.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->chart_studio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->chart_studio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->chart_studio) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->chart_studio) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ac04ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ebc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import re\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "nltk.download('all')\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_content = re.sub('[^,.?![A-Za-z\\s]+','', str(kpr_data))\n",
    "filtered_content = filtered_content.lower()\n",
    "word_tokens = nltk.word_tokenize(filtered_content)\n",
    "tokens_pos = nltk.pos_tag(word_tokens) \n",
    "NN_words2 = []\n",
    "\n",
    "for word, pos in tokens_pos:\n",
    "    if 'VB' in pos:\n",
    "        NN_words2.append(word)\n",
    "a = [\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"have\", \"has\", \"had\", \"been\"]\n",
    "kpr_nouns = [i for i in NN_words2 if i not in a]\n",
    "df_kpr = pd.DataFrame({\"word\" : kpr_nouns})\n",
    "df_kpr[\"count\"] = df_kpr[\"word\"].str.len()\n",
    "df_kpr = df_kpr[df_kpr[\"count\"] >= 2]\n",
    "df_kpr.sort_values(\"count\")\n",
    "df_kpr = df_kpr.groupby(\"word\", as_index = False).agg(n = (\"word\", \"count\")).sort_values(\"n\", ascending = False)\n",
    "kpr_top30 = df_kpr.head(30)\n",
    "kpr_top30 = kpr_top30.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_content = re.sub('[^,.?![A-Za-z\\s]+','', str(kcs_data))\n",
    "filtered_content = filtered_content.lower()\n",
    "word_tokens = nltk.word_tokenize(filtered_content)\n",
    "tokens_pos = nltk.pos_tag(word_tokens) \n",
    "NN_words = []\n",
    "\n",
    "for word, pos in tokens_pos:\n",
    "    if 'VB' in pos:\n",
    "        NN_words.append(word)    \n",
    "a = [\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"have\", \"has\", \"had\", \"been\"]\n",
    "kcs_nouns = [i for i in NN_words if i not in a]\n",
    "df_kpr = pd.DataFrame({\"word\" : kpr_nouns})\n",
    "df_kpr[\"count\"] = df_kpr[\"word\"].str.len()\n",
    "df_kpr = df_kpr[df_kpr[\"count\"] >= 2]\n",
    "df_kpr.sort_values(\"count\")\n",
    "df_kpr = df_kpr.groupby(\"word\", as_index = False).agg(n = (\"word\", \"count\")).sort_values(\"n\", ascending = False)\n",
    "kpr_top30 = df_kpr.head(30)\n",
    "kpr_top30 = kpr_top30.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_content = re.sub('[^,?![A-Za-z\\s]+','', str(jpcs_data))\n",
    "filtered_content = filtered_content.lower()\n",
    "word_tokens = nltk.word_tokenize(filtered_content)\n",
    "tokens_pos = nltk.pos_tag(word_tokens) \n",
    "jp_words = []\n",
    "\n",
    "for word, pos in tokens_pos:\n",
    "    if 'VB' in pos:\n",
    "        jp_words.append(word)\n",
    "a = [\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"have\", \"has\", \"had\", \"been\"]\n",
    "jpcs_nouns = [i for i in jp_words if i not in a]\n",
    "df_jpcs = pd.DataFrame({\"word\" : jpcs_nouns})\n",
    "df_jpcs[\"count\"] = df_jpcs[\"word\"].str.len()\n",
    "df_jpcs = df_jpcs[df_jpcs[\"count\"] >= 2]\n",
    "df_jpcs.sort_values(\"count\")\n",
    "df_jpcs = df_jpcs.groupby(\"word\", as_index = False).agg(n = (\"word\", \"count\")).sort_values(\"n\", ascending = False)\n",
    "jpcs_top30 = df_jpcs.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_content = re.sub('[^,?![A-Za-z\\s]+','', str(jppr_data))\n",
    "filtered_content = filtered_content.lower()\n",
    "word_tokens = nltk.word_tokenize(filtered_content)\n",
    "tokens_pos = nltk.pos_tag(word_tokens) \n",
    "jp_words2 = []\n",
    "\n",
    "for word, pos in tokens_pos:\n",
    "    if 'VB' in pos:\n",
    "        jp_words2.append(word)\n",
    "a = [\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"have\", \"has\", \"had\", \"been\"]\n",
    "jppr_nouns = [i for i in jp_words2 if i not in a]\n",
    "df_jppr = pd.DataFrame({\"word\" : jppr_nouns})\n",
    "df_jppr[\"count\"] = df_jppr[\"word\"].str.len()\n",
    "df_jppr = df_jppr[df_jppr[\"count\"] >= 2]\n",
    "df_jppr.sort_values(\"count\")\n",
    "df_jppr = df_jppr.groupby(\"word\", as_index = False).agg(n = (\"word\", \"count\")).sort_values(\"n\", ascending = False)\n",
    "jppr_top30 = df_jppr.head(30)\n",
    "jppr_top30 = jppr_top30.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_content = re.sub('[^,?![A-Za-z\\s]+','', str(cn_data))\n",
    "filtered_content = filtered_content.lower()\n",
    "word_tokens = nltk.word_tokenize(filtered_content)\n",
    "tokens_pos = nltk.pos_tag(word_tokens) \n",
    "cn_words = []\n",
    "\n",
    "for word, pos in tokens_pos:\n",
    "    if 'VB' in pos:\n",
    "        cn_words.append(word)\n",
    "a = [\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"have\", \"has\", \"had\", \"been\"]\n",
    "cn_nouns = [i for i in cn_words if i not in a]\n",
    "df_cn = pd.DataFrame({\"word\" : cn_nouns})\n",
    "df_cn[\"count\"] = df_cn[\"word\"].str.len()\n",
    "df_cn = df_cn[df_cn[\"count\"] >= 2]\n",
    "df_cn.sort_values(\"count\")\n",
    "df_cn = df_cn.groupby(\"word\", as_index = False).agg(n = (\"word\", \"count\")).sort_values(\"n\", ascending = False)\n",
    "cn_top30 = df_cn.head(30)\n",
    "cn_top30 = cn_top30.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_content = re.sub('[^A-Za-z\\s]+','', str(rs_data))\n",
    "filtered_content = filtered_content.lower()\n",
    "word_tokens = nltk.word_tokenize(filtered_content)\n",
    "tokens_pos = nltk.pos_tag(word_tokens) \n",
    "rs_words = []\n",
    "\n",
    "for word, pos in tokens_pos:\n",
    "    if 'VB' in pos:\n",
    "        rs_words.append(word)\n",
    "a = [\"is\", \"am\", \"are\", \"was\", \"were\", \"be\", \"have\", \"has\", \"had\", \"been\"]\n",
    "rs_nouns = [i for i in rs_words if i not in a]\n",
    "df_rs = pd.DataFrame({\"word\" : rs_nouns})\n",
    "df_rs[\"count\"] = df_rs[\"word\"].str.len()\n",
    "df_rs = df_rs[df_rs[\"count\"] >= 2]\n",
    "df_rs.sort_values(\"count\")\n",
    "df_rs = df_rs.groupby(\"word\", as_index = False).agg(n = (\"word\", \"count\")).sort_values(\"n\", ascending = False)\n",
    "rs_top30 = df_rs.head(30)\n",
    "rs_top30 = rs_top30.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_kor = pd.concat([kcs_top30, kpr_top30], axis=1)\n",
    "merged_df_kor.columns = [\"kcs_word\", \"kcs_count\", \"kpr_word\",\"kpr_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630718ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_jp = pd.concat([jpcs_top30, jppr_top30], axis=1)\n",
    "merged_df_jp.columns = [\"jpcs_word\", \"jpcs_count\", \"jppr_word\",\"jppr_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "fig.add_trace(go.Bar(x=merged_df_kor['kcs_word'], y=merged_df_kor['kcs_count'], name='Korea conservative media company'), row = 1, col = 1)\n",
    "fig.add_trace(go.Bar(x=merged_df_kor['kpr_word'], y=merged_df_kor['kpr_count'], name='Korea progressive media company'), row = 1, col = 1)\n",
    "fig.add_trace(go.Bar(x=merged_df_kor['kpr_word'], y=merged_df_kor['kpr_count'], name='Korea progressive media company'), row = 2, col = 1)\n",
    "fig.add_trace(go.Bar(x=merged_df_kor['kcs_word'], y=merged_df_kor['kcs_count'], name='Korea conservative media company'), row = 2, col = 1)\n",
    "fig.update_layout(title_text='Comparison of Korean media companies', width=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "fig.add_trace(go.Bar(x=merged_df_jp['jpcs_word'], y=merged_df_jp['jpcs_count'], name='Japan conservative media company'), row = 1, col = 1)\n",
    "fig.add_trace(go.Bar(x=merged_df_jp['jppr_word'], y=merged_df_jp['jppr_count'], name='Japan progressive media company'), row = 1, col = 1)\n",
    "fig.add_trace(go.Bar(x=merged_df_jp['jppr_word'], y=merged_df_jp['jppr_count'], name='Japan progressive media company'), row = 2, col = 1)\n",
    "fig.add_trace(go.Bar(x=merged_df_jp['jpcs_word'], y=merged_df_jp['jpcs_count'], name='Japan conservative media company'), row = 2, col = 1)\n",
    "fig.update_layout(title_text='Comparison of Japanese media companies', width=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db17b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1)\n",
    "fig.add_trace(go.Bar(x=kpr_top30['word'], y=kpr_top30['n'], name='Korea progressive media company'),row = 1, col = 1)\n",
    "fig.add_trace(go.Bar(x=kpr_top30['word'], y=jppr_top30['n'], name='Japan progressive media company'),row = 1, col = 1)\n",
    "fig.add_trace(go.Bar(x=jpcs_top30['word'], y=jpcs_top30['n'], name='Korea conservative media company'),row = 2, col = 1)\n",
    "fig.add_trace(go.Bar(x=jpcs_top30['word'], y=kcs_top30['n'], name='Japan conservative media company'),row = 2, col = 1)\n",
    "fig.update_layout(title_text='Comparison between Korea and Japan', width=1200)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4113e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=4, cols=1)\n",
    "fig.add_trace(go.Bar(x=kcs_top30['word'], y=kcs_top30['n'], name='Korea conservative media company'), row = 1, col = 1)\n",
    "fig.add_trace(go.Bar(x=jpcs_top30['word'], y=jpcs_top30['n'], name='Japan conservative media company'), row = 2, col = 1)\n",
    "fig.add_trace(go.Bar(x=cn_top30['word'], y=cn_top30['n'], name='China conservative media company'), row = 3, col = 1)\n",
    "fig.add_trace(go.Bar(x=rs_top30['word'], y=rs_top30['n'], name='Russia conservative media company'), row = 4, col = 1)\n",
    "fig.update_layout(title_text='Conservative media by country', width=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=kcs_top30['word'], y=kcs_top30['n'], name='Korea conservative media company'))\n",
    "fig.add_trace(go.Bar(x=kcs_top30['word'], y=jpcs_top30['n'], name='Japan conservative media company'))\n",
    "fig.add_trace(go.Bar(x=kcs_top30['word'], y=cn_top30['n'], name='China conservative media company'))\n",
    "fig.add_trace(go.Bar(x=kcs_top30['word'], y=rs_top30['n'], name='Russia conservative media company'))\n",
    "fig.update_layout(title_text='Conservative media by country', width=1000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2221154",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['kor_cons', 'kor_pr', 'p_cons', 'jp_pr', 'cn_cons', 'rs_cons']\n",
    "values = [-0.405941, -0.730496, -0.582090, -0.366667, -0.365854, 0.076923]\n",
    "\n",
    "fig = px.bar(x=values, y=labels, orientation='h', text=values, color=values,\n",
    "             labels={'x': 'Scores', 'y': 'Category'}, title=\"Sentiment Score\")\n",
    "fig.update_layout(xaxis=dict(range=[-1, 1]), xaxis_title=\"Scores\", yaxis_title=\"Category\",\n",
    "                  yaxis_categoryorder='total ascending', yaxis={'categoryarray': labels[::-1]})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcs_sentiment_firm = []\n",
    "sentiment = 0\n",
    "count = 0\n",
    "for token in kcs_nouns:\n",
    "    if token in positive_words:\n",
    "        sentiment += 1\n",
    "        count += 1\n",
    "    elif token in negative_words:\n",
    "        sentiment -= 1\n",
    "        count += 1\n",
    "kpr_sentiment_firm.append(sentiment/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae208f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpr_sentiment_firm = []\n",
    "sentiment = 0\n",
    "count = 0\n",
    "for token in kpr_nouns:\n",
    "    if token in positive_words:\n",
    "        sentiment += 1\n",
    "        count += 1\n",
    "    elif token in negative_words:\n",
    "        sentiment -= 1\n",
    "        count += 1\n",
    "kpr_sentiment_firm.append(sentiment/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa59ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpcs_sentiment_firm = []\n",
    "sentiment = 0\n",
    "count = 0\n",
    "for token in jpcs_nouns:\n",
    "    if token in positive_words:\n",
    "        sentiment += 1\n",
    "        count += 1\n",
    "    elif token in negative_words:\n",
    "        sentiment -= 1\n",
    "        count += 1\n",
    "jpcs_sentiment_firm.append(sentiment/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "jppr_sentiment_firm = []\n",
    "sentiment = 0\n",
    "count = 0\n",
    "for token in jppr_nouns:\n",
    "    if token in positive_words:\n",
    "        sentiment += 1\n",
    "        count += 1\n",
    "    elif token in negative_words:\n",
    "        sentiment -= 1\n",
    "        count += 1\n",
    "jppr_sentiment_firm.append(sentiment/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28f2e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_sentiment_firm = []\n",
    "sentiment = 0\n",
    "count = 0\n",
    "for token in cn_nouns:\n",
    "    if token in positive_words:\n",
    "        sentiment += 1\n",
    "        count += 1\n",
    "    elif token in negative_words:\n",
    "        sentiment -= 1\n",
    "        count += 1\n",
    "cn_sentiment_firm.append(sentiment/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_sentiment_firm = []\n",
    "sentiment = 0\n",
    "count = 0\n",
    "for token in rs_nouns:\n",
    "    if token in positive_words:\n",
    "        sentiment += 1\n",
    "        count += 1\n",
    "    elif token in negative_words:\n",
    "        sentiment -= 1\n",
    "        count += 1\n",
    "rs_sentiment_firm.append(sentiment/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a24cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['kor_cons', 'kor_pr', 'p_cons', 'jp_pr', 'cn_cons', 'rs_cons']\n",
    "values = [-0.405941, -0.730496, -0.582090, -0.366667, -0.365854, 0.076923]\n",
    "# 그래프 생성\n",
    "fig = px.bar(x=values, y=labels, orientation='h', text=values, color=values,\n",
    "             labels={'x': 'Scores', 'y': 'Category'}, title=\"Sentiment Score\")\n",
    "# 레이아웃 설정\n",
    "fig.update_layout(xaxis=dict(range=[-1, 1]), xaxis_title=\"Scores\", yaxis_title=\"Category\",\n",
    "                  yaxis_categoryorder='total ascending', yaxis={'categoryarray': labels[::-1]})\n",
    "# 그래프 출력\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b81689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df, names=df.columns, values=df.iloc[0], title='Sentiment Analysis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "point = 0\n",
    "for i in kcs_nouns:\n",
    "    if i in positive_words:\n",
    "        point += 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in kcs_nouns:\n",
    "    if i in negative_words:\n",
    "        point -= 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in kpr_nouns:\n",
    "    if i in positive_words:\n",
    "        point += 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in kpr_nouns:\n",
    "    if i in negative_words:\n",
    "        point -= 1\n",
    "print(str((point/961)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafedb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in jpcs_nouns:\n",
    "    if i in positive_words:\n",
    "        point += 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in jpcs_nouns:\n",
    "    if i in negative_words:\n",
    "        point -= 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in jppr_nouns:\n",
    "    if i in positive_words:\n",
    "        point += 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in jppr_nouns:\n",
    "    if i in negative_words:\n",
    "        point -= 1\n",
    "print(str((point/961)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cn_nouns:\n",
    "    if i in positive_words:\n",
    "        point += 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in cn_nouns:\n",
    "    if i in negative_words:\n",
    "        point -= 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in rs_nouns:\n",
    "    if i in positive_words:\n",
    "        point += 1\n",
    "print(str((point/961)*100))\n",
    "point = 0\n",
    "for i in rs_nouns:\n",
    "    if i in negative_words:\n",
    "        point -= 1\n",
    "print(str((point/961)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e9dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'kcs_positive':[5.30697190426639],'kcs_negative':[26.84703433922997], \"kpr_positive\" : [4.266389177939646], \"kpr_negative\" : [26.84703433922997], \"jpcs_positive\" : [5.30697190426639], \"jpcs_negative\" : [12.278876170655566], \"jppr_positive\" : [2.6014568158168574], \"jppr_negative\" : [5.6191467221644125], \"cn_positive\" : [2.705515088449532], \"cn_negative\" : [7.075962539021852], \"rs_positive\" : [6.659729448491156], \"rs_negative\" : [7.075962539021852]})\n",
    "\n",
    "fig = px.pie(df, names=df.columns, values=df.iloc[0], title='Sentiment Analysis')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e5c230",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Category': ['kor_cons', 'kor_pr', 'p_cons', 'jp_pr', 'cn_cons', 'rs_cons'],\n",
    "    'Positive': [5.30697190426639, 4.266389177939646, 5.30697190426639, 2.6014568158168574, 2.705515088449532, 6.659729448491156],\n",
    "    'Negative': [-26.84703433922997, -26.84703433922997, -12.278876170655566, -5.6191467221644125, -7.075962539021852, -7.075962539021852]\n",
    "}\n",
    "\n",
    "df_1 = pd.DataFrame(data)\n",
    "# 데이터프레임을 'melt' 함수를 사용하여 재구성합니다.\n",
    "df_melted = pd.melt(df_1, id_vars=['Category'], value_vars=['Positive', 'Negative'],\n",
    "                    var_name='Sentiment', value_name='Score')\n",
    "# 그래프 생성\n",
    "fig = px.bar(df_melted, x='Score', y='Category', orientation='h', color='Sentiment',\n",
    "             labels={'Score': 'Scores', 'Category': 'Category'}, title=\"Sentiment Score\")\n",
    "# 그래프 스타일 및 레이아웃 설정\n",
    "fig.update_layout(xaxis=dict(range=[-30, 10]), xaxis_title=\"Scores\", yaxis_title=\"Category\",\n",
    "                  yaxis_categoryorder='total ascending', yaxis={'categoryarray': df_melted['Category'][::-1]})\n",
    "# 그래프 출력\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f91ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c81739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf090aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6a406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44c99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf09c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60447d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d6e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678e025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9a268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78a795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57547f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe74c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a02b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90aad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb128b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72199cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08036b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
